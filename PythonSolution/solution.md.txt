Lab3 REPORT

I collaborated with Anusha Gupta (angu5645@colorado.edu)

Configuration of dataproc cluster: 
1 master node
2 worker nodes

No. of mappers: 3
No. of reducers: 3

Mapper1:
1) Take input of both files: apat63_99.txt and cite75_99.txt [from input folder in hdfs]=> input is read line by line.
We differentiate between the 2 files by length of each line read: len(line) = 2 for cite75_99.txt
and len(line) = 11 for apat63_99.txt
2) Mapper1 outputs CITING CITED
		   PATENT_NUMBER,<field2>,<field3>,,,,,,
		   .
		   .
		   .
3) Output from mapper1 is sorted and fed to reducer 1 (through stdin).

Reducer1:
1) Receives CITING in sorted order after which we use join here to find the corresponding CITING state.
2) Reducer 1 outputs CITING CITED CITING_STATE
		     .
                     .
                     .
The output is merged and copied to input folder.
We delete cite75_99.txt from input folder.

Mapper 2:
1) Reads the apat63_99.txt and output files from reducer 1 copied into input folder.
Now, CITED should be the key for 2nd reducer.
2) Mapper 2 outputs CITED CITING CITING_STATE
		    PATENT_NUMBER, <field 2>, <field 3>,,,,,,
		    .
		    .
		    .

Reducer 2:
1) Receives CITED in sorted order and we perform join to find corresponding CITED STATE.
2) Reducer 2 outputs CITED CITING CITING_STATE CITED_STATE
		     .
                     .
                     .

The output is merged and copied into input folder.

Mapper 3:
1) Reads apat63_99.txt and output files copied from reducer2 into input folder.
Now, CITING should be the key for 3rd reducer join.
2) Mapper 3 outputs CITING CITING_STATE CITED_STATE
		    PATENT_NUMBER, <field2>, <field3>,,,,,,
		    .
		    .
	            .
Reducer 3:
1) Receives CITING in sorted order and we perform join to count no. of citations from same originating
state for each CITING.
2) Reducer 3 outputs PATENT_NUMBER, <field 1>, <field 2>,,,,,,,,,,<Count of same state citations>
		     .
		     .
		     .


Note: stream-output folder is deleted each time before running hadoop stream job.

MAKEFILE
make stream triggers RUN-MAP-REDUCE-1 shell script, which has the following:
1) Intially, we copy apat63_99.txt and cite75_99.txt into input folder.
2) Run mapper1 which read line by line from each file in input folder.
3) Output for reducer1 is taken from output of mapper1 through stdin.
4) We copy merge output files generated by reducer1 into 1 output file which is copied to input folder and we delete cite75_99.txt from input folder. 
This is the sequence of steps which is repeated for chaining the remaining mapreduce jobs.
